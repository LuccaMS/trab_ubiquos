{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('../best.pt')\n",
    "imgs = []\n",
    "filenames = sorted(os.listdir('imgs_test'), key=lambda x: int(x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    with open(f'imgs_test/{filename}', 'rb') as f:\n",
    "        imgs.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_image(byte_data):\n",
    "    np_arr = np.frombuffer(byte_data, np.uint8)\n",
    "    image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    print(type(image))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_y = 50\n",
    "entry_count = 0\n",
    "exit_count = 0\n",
    "confidence_threshold = 0.9\n",
    "previous_positions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_track(frames):\n",
    "    global entry_count, exit_count, previous_positions\n",
    "    for byte_data in frames:\n",
    "        # Convert byte data to image\n",
    "        frame = bytes_to_image(byte_data)\n",
    "        # Ensure the frame was converted successfully\n",
    "        if frame is None:\n",
    "            continue\n",
    "        # Track objects in the frame\n",
    "        results = model.track(source=frame,device=0) # usando a gpu em 0\n",
    "        \n",
    "        # Process the tracking results (e.g., draw bounding boxes)\n",
    "        current_positions = {}\n",
    "        \n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                confidence = box.conf[0].item()\n",
    "\n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])\n",
    "                #mudanÃ§a try catch\n",
    "                try:\n",
    "                    object_id = int(box.id[0])  # Assuming 'id' contains the unique ID\n",
    "                except:\n",
    "                    object_id = 0\n",
    "                \n",
    "                # Calculate the center of the bounding box\n",
    "                center_y = (y1 + y2) // 2\n",
    "                \n",
    "                # Store the current position\n",
    "                current_positions[object_id] = center_y\n",
    "                \n",
    "                # Draw the bounding box on the frame\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "                #cv2.putText(frame, f'{confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "        # Check for entries and exits\n",
    "        for object_id, center_y in current_positions.items():\n",
    "            if object_id in previous_positions:\n",
    "                previous_y = previous_positions[object_id]\n",
    "                \n",
    "                # Check if the object has crossed the boundary\n",
    "                if previous_y <= boundary_y < center_y:\n",
    "                    entry_count += 1\n",
    "                elif previous_y >= boundary_y > center_y:\n",
    "                    exit_count += 1\n",
    "        \n",
    "        # Update previous positions\n",
    "        previous_positions = current_positions\n",
    "        \n",
    "        # Draw the boundary line\n",
    "        cv2.line(frame, (0, boundary_y), (frame.shape[1], boundary_y), (0, 255, 0), 2)\n",
    "        \n",
    "        resized_frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "        cv2.putText(resized_frame, f'Entries: {entry_count}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2)\n",
    "        cv2.putText(resized_frame, f'Exits: {exit_count}', (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)\n",
    "    \n",
    "        # Display the frame (optional, for visualization purposes)\n",
    "        cv2.imshow('Tracked Frame', resized_frame)\n",
    "        #time.sleep(0.25)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 79.8ms\n",
      "Speed: 4.0ms preprocess, 79.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 80.8ms\n",
      "Speed: 5.0ms preprocess, 80.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 75.8ms\n",
      "Speed: 3.0ms preprocess, 75.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 4.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 69.8ms\n",
      "Speed: 3.0ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 6.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 (no detections), 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 71.8ms\n",
      "Speed: 3.0ms preprocess, 71.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 72.8ms\n",
      "Speed: 4.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 71.8ms\n",
      "Speed: 6.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 72.8ms\n",
      "Speed: 4.0ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 73.8ms\n",
      "Speed: 4.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 5.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 2 persons, 73.8ms\n",
      "Speed: 4.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 71.8ms\n",
      "Speed: 4.0ms preprocess, 71.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 4.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 71.8ms\n",
      "Speed: 4.0ms preprocess, 71.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "0: 640x640 1 person, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "process_and_track(imgs)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
