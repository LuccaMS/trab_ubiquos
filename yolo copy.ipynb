{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('../best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(os.listdir('imgs_test'), key=lambda x: int(x.split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each image, convert it to a byte array, and append to the list\n",
    "for filename in filenames:\n",
    "    with open(f'imgs_test/{filename}', 'rb') as f:\n",
    "        imgs.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert byte data to an image\n",
    "def bytes_to_image(byte_data):\n",
    "    np_arr = np.frombuffer(byte_data, np.uint8)\n",
    "    image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    print(type(image))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [ 45,  45,  45],\n",
       "        [ 50,  50,  50],\n",
       "        [ 51,  51,  51]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [ 44,  44,  44],\n",
       "        [ 48,  48,  48],\n",
       "        [ 49,  49,  49]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [ 41,  41,  41],\n",
       "        [ 47,  47,  47],\n",
       "        [ 49,  49,  49]]], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = np.frombuffer(imgs[0], np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the entry/exit boundary line (e.g., a horizontal line at y=250)\n",
    "boundary_y = 50\n",
    "entry_count = 0\n",
    "exit_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_positions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_track(frames):\n",
    "    global entry_count, exit_count, previous_positions\n",
    "    \n",
    "    for byte_data in frames:\n",
    "        # Convert byte data to image\n",
    "        frame = bytes_to_image(byte_data)\n",
    "        \n",
    "        # Ensure the frame was converted successfully\n",
    "        if frame is None:\n",
    "            continue\n",
    "        \n",
    "        # Track objects in the frame\n",
    "        results = model.track(source=frame)\n",
    "        \n",
    "        # Process the tracking results (e.g., draw bounding boxes)\n",
    "        current_positions = {}\n",
    "        \n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                confidence = box.conf[0].item()\n",
    "\n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])\n",
    "                object_id = int(box.id[0])  # Assuming 'id' contains the unique ID\n",
    "                \n",
    "                # Calculate the center of the bounding box\n",
    "                center_y = (y1 + y2) // 2\n",
    "                \n",
    "                # Store the current position\n",
    "                current_positions[object_id] = center_y\n",
    "                \n",
    "                # Draw the bounding box on the frame\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                #cv2.putText(frame, f'ID: {object_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                #cv2.putText(frame, f'{confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        # Check for entries and exits\n",
    "        for object_id, center_y in current_positions.items():\n",
    "            if object_id in previous_positions:\n",
    "                previous_y = previous_positions[object_id]\n",
    "                \n",
    "                # Check if the object has crossed the boundary\n",
    "                if previous_y <= boundary_y < center_y:\n",
    "                    entry_count += 1\n",
    "                elif previous_y >= boundary_y > center_y:\n",
    "                    exit_count += 1\n",
    "        \n",
    "        # Update previous positions\n",
    "        previous_positions = current_positions\n",
    "        \n",
    "        # Draw the boundary line\n",
    "        cv2.line(frame, (0, boundary_y), (frame.shape[1], boundary_y), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display the counts with smaller font size\n",
    "        cv2.putText(frame, f'Entries: {entry_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "        cv2.putText(frame, f'Exits: {exit_count}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "        # Resize the frame to 500x500 pixels\n",
    "        resized_frame = cv2.resize(frame, (500, 500))\n",
    "        \n",
    "        # Display the frame (optional, for visualization purposes)\n",
    "        cv2.imshow('Tracked Frame', resized_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_track(imgs)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
