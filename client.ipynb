{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import websockets\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('../best.pt')\n",
    "# Define the entry/exit boundary line (e.g., a horizontal line at y=250)\n",
    "boundary_y = 50\n",
    "entry_count = 0\n",
    "exit_count = 0\n",
    "\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "previous_positions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(byte_data):\n",
    "    byteArray = bytearray()\n",
    "    byteArray.extend(byte_data)\n",
    "    flatNumpyArray = np.array(byteArray)\n",
    "    img = flatNumpyArray.reshape(100,100)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_track(byte_data):\n",
    "    global entry_count, exit_count, previous_positions\n",
    "    \n",
    "    # Convert byte data to image\n",
    "    frame = process_image(byte_data)\n",
    "    \n",
    "    # Ensure the frame was converted successfully\n",
    "    if frame is None:\n",
    "        return\n",
    "    \n",
    "    # Track objects in the frame\n",
    "    results = model.track(source=frame)\n",
    "    \n",
    "    # Process the tracking results (e.g., draw bounding boxes)\n",
    "    current_positions = {}\n",
    "    \n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            confidence = box.conf[0].item()\n",
    "\n",
    "            if confidence < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])\n",
    "            object_id = int(box.id[0])  # Assuming 'id' contains the unique ID\n",
    "            \n",
    "            # Calculate the center of the bounding box\n",
    "            center_y = (y1 + y2) // 2\n",
    "            \n",
    "            # Store the current position\n",
    "            current_positions[object_id] = center_y\n",
    "            \n",
    "            # Draw the bounding box on the frame\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            #cv2.putText(frame, f'ID: {object_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            #cv2.putText(frame, f'{confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Check for entries and exits\n",
    "    for object_id, center_y in current_positions.items():\n",
    "        if object_id in previous_positions:\n",
    "            previous_y = previous_positions[object_id]\n",
    "            \n",
    "            # Check if the object has crossed the boundary\n",
    "            if previous_y <= boundary_y < center_y:\n",
    "                entry_count += 1\n",
    "            elif previous_y >= boundary_y > center_y:\n",
    "                exit_count += 1\n",
    "    \n",
    "    # Update previous positions\n",
    "    previous_positions = current_positions\n",
    "    \n",
    "    # Draw the boundary line\n",
    "    cv2.line(frame, (0, boundary_y), (frame.shape[1], boundary_y), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the counts with smaller font size\n",
    "    cv2.putText(frame, f'Entries: {entry_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    cv2.putText(frame, f'Exits: {exit_count}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    # Resize the frame to 500x500 pixels\n",
    "    resized_frame = cv2.resize(frame, (500, 500))\n",
    "    return resized_frame\n",
    "    # Display the frame (optional, for visualization purposes)\n",
    "    #cv2.imshow('Tracked Frame', resized_frame)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(byte_data):\n",
    "    byteArray = bytearray()\n",
    "    byteArray.extend(byte_data)\n",
    "    flatNumpyArray = np.array(byteArray)\n",
    "    grayImage = flatNumpyArray.reshape(100,100)\n",
    "    grayImage = cv2.resize(grayImage, (500,500))\n",
    "    return grayImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import websockets\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def handle_data(websocket, path):\n",
    "    async for message in websocket:\n",
    "        #img = show_image(message)\n",
    "        #keep showing the imgs with cv2\n",
    "        #cv2.imshow('image', img)\n",
    "        #cv2.waitKey(1)\n",
    "        img_inferred = process_and_track(message)\n",
    "\n",
    "        if img_inferred != None:\n",
    "            cv2.imshow('image', img_inferred)\n",
    "            cv2.waitKey(1)\n",
    "        else:\n",
    "            print('Error processing image')\n",
    "\n",
    "#192.168.3.3\n",
    "# para testes locais pegar o IPV4\n",
    "start_server = websockets.serve(handle_data, \"192.168.3.3\", 999)\n",
    "\n",
    "# This ensures the server keeps running until it's explicitly stopped\n",
    "asyncio.get_event_loop().run_until_complete(start_server)\n",
    "asyncio.get_event_loop().run_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
